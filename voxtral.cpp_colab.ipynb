{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Voxtral.cpp on Google Colab\n",
        "\n",
        "This notebook runs [Voxtral.cpp](https://github.com/andrijdavid/voxtral.cpp) - a ggml-based C++ implementation of Voxtral Realtime 4B.\n",
        "\n",
        "The model performs audio inference on 16-bit PCM WAV files at 16kHz (mono)."
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup and Installation"
      ],
      "metadata": {
        "id": "setup-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required dependencies\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq cmake build-essential ffmpeg git"
      ],
      "metadata": {
        "id": "install-deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repository with submodules\n",
        "!git clone --recursive https://github.com/andrijdavid/voxtral.cpp.git\n",
        "%cd voxtral.cpp"
      ],
      "metadata": {
        "id": "clone-repo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If submodules weren't initialized, do it manually\n",
        "!git submodule update --init --recursive"
      ],
      "metadata": {
        "id": "init-submodules"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Build the Project"
      ],
      "metadata": {
        "id": "build-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build with CMake\n",
        "!cmake -B build -DCMAKE_BUILD_TYPE=Release\n",
        "!cmake --build build -j$(nproc)"
      ],
      "metadata": {
        "id": "build-project"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Download the Model\n",
        "\n",
        "Downloads the Q4_0 quantized GGUF model from Hugging Face."
      ],
      "metadata": {
        "id": "model-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the pre-converted GGUF model (Q4_0 quantization)\n",
        "!chmod +x ./tools/download_model.sh\n",
        "!./tools/download_model.sh Q4_0"
      ],
      "metadata": {
        "id": "download-model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Audio Processing Utilities"
      ],
      "metadata": {
        "id": "audio-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shlex\n",
        "import subprocess\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import files\n",
        "\n",
        "def convert_audio_to_wav(input_file, output_file=\"input.wav\"):\n",
        "    \"\"\"\n",
        "    Convert audio and display the full FFmpeg log.\n",
        "    \"\"\"\n",
        "    safe_input = shlex.quote(input_file)\n",
        "\n",
        "    cmd = f\"ffmpeg -i {safe_input} -ar 16000 -ac 1 -c:a pcm_s16le {output_file} -y 2>&1\"\n",
        "\n",
        "    print(\"--- Starting FFmpeg Log ---\")\n",
        "    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "\n",
        "    for line in process.stdout:\n",
        "        print(line.strip())\n",
        "\n",
        "    process.wait()\n",
        "    print(\"--- End of FFmpeg Log ---\\n\")\n",
        "\n",
        "    if os.path.exists(output_file) and os.path.getsize(output_file) > 0:\n",
        "        print(f\"✓ Success: {output_file} created.\")\n",
        "        return output_file\n",
        "    else:\n",
        "        print(f\"✗ Error: {output_file} was not created or is empty.\")\n",
        "        return None\n",
        "\n",
        "def upload_audio():\n",
        "    print(\"Please upload your audio file...\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        filename = list(uploaded.keys())[0]\n",
        "        print(f\"✓ Uploaded: {filename}\")\n",
        "        return filename\n",
        "    return None"
      ],
      "metadata": {
        "id": "audio-utils"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Upload and Convert Your Audio (Max 30s)"
      ],
      "metadata": {
        "id": "upload-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your audio file\n",
        "audio_file = upload_audio()\n",
        "\n",
        "if audio_file:\n",
        "    # Convert to the required format\n",
        "    wav_file = convert_audio_to_wav(audio_file)\n",
        "\n",
        "    # Only display if the conversion actually worked\n",
        "    if wav_file:\n",
        "        print(\"\\nYour audio:\")\n",
        "        display(Audio(filename=wav_file))\n",
        "    else:\n",
        "        print(\"\\nConversion failed. Please check the filename or ffmpeg logs.\")"
      ],
      "metadata": {
        "id": "upload-convert"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Run Inference\n",
        "\n",
        "Process the audio file using Voxtral.cpp."
      ],
      "metadata": {
        "id": "inference-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference\n",
        "MODEL_PATH = \"models/voxtral/Q4_0.gguf\"\n",
        "AUDIO_PATH = \"input.wav\"  # or use the wav_file variable\n",
        "THREADS = 8\n",
        "\n",
        "!./build/voxtral \\\n",
        "  --model {MODEL_PATH} \\\n",
        "  --audio {AUDIO_PATH} \\\n",
        "  --threads {THREADS}"
      ],
      "metadata": {
        "id": "run-inference"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Alternative: Use Sample Audio\n",
        "\n",
        "If you want to test with sample audio files included in the repository:"
      ],
      "metadata": {
        "id": "samples-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List available sample files\n",
        "!ls -lh samples/*.wav 2>/dev/null || echo \"No sample files found\""
      ],
      "metadata": {
        "id": "list-samples"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference on a sample file (update the path if needed)\n",
        "SAMPLE_FILE = \"samples/8297-275156-0000.wav\"  # Change to your sample file\n",
        "\n",
        "!./build/voxtral \\\n",
        "  --model {MODEL_PATH} \\\n",
        "  --audio {SAMPLE_FILE} \\\n",
        "  --threads {THREADS}"
      ],
      "metadata": {
        "id": "run-sample"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}